{
  "comments": "90,750 in CoNLL-2005 training corpus, 1135 steps w/ batch size of 80 is ~1 epoch",
  "reader": "conll_2005",
  "checkpoint_steps": 1135,
  "patience": 200000,
  "max_steps": 500000,
  "batch_size": 80,
  "ema_decay": 0.999,
  "bucket_sizes": [
    20,
    30,
    50,
    80
  ],
  "optimizer": {
    "name": "Adadelta",
    "params": {
      "epsilon": 1e-6
    },
    "lr": 1.0,
    "clip": 1.0,
    "l2_loss": {
      ".*module/aggregation/weights.*": 0.001
    }
  },
  "features": {
    "seq_feat": "gold",
    "targets": [
      {
        "name": "gold",
        "key": "gold",
        "indices": {
          "O": 0
        },
        "unknown_word": "O",
        "pad_word": "O"
      }
    ],
    "inputs": [
      {
        "name": "elmo",
        "key": "word",
        "config": {
          "dropout": 0.1
        }
      },
      {
        "name": "marker",
        "key": "marker",
        "config": {
          "dim": 100
        },
        "indices": {
          "0": 0
        },
        "unknown_word": "0",
        "pad_word": "0"
      }
    ]
  },
  "encoders": [
    {
      "name": "tokens",
      "type": "concat",
      "inputs": [
        "word",
        "elmo",
        "marker"
      ],
      "input_dropout": 0.0
    },
    {
      "name": "alternating_lstm",
      "inputs": [
        "tokens"
      ],
      "type": "dblstm",
      "state_size": 300,
      "encoder_output_dropout": 0.1,
      "encoder_layers": 8
    }
  ],
  "heads": [
    {
      "encoder": "alternating_lstm",
      "name": "gold",
      "type": "srl",
      "label_smoothing": 0.1
    }
  ]
}