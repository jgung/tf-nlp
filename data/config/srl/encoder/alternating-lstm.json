{
  "name": "alternating_lstm",
  "inputs": [
    "tokens"
  ],
  "type": "dblstm",
  "state_size": 300,
  "encoder_output_dropout": 0.1,
  "encoder_layers": 8
}