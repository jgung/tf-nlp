{
  "comments": "90,750 in CoNLL-2005 training corpus, 2800 steps w/ batch size of 32 is about 1 epoch, 70900 steps is 25 epochs",
  "reader": "conll_2005",
  "checkpoint_steps": 2800,
  "patience": 70000,
  "max_steps": 1000000,
  "batch_size": 32,
  "ema_decay": 0.999,
  "bucket_sizes": [
    20,
    30,
    50,
    80
  ],
  "optimizer": {
    "name": "Adadelta",
    "params": {
      "epsilon": 1e-6
    },
    "lr": 1.0,
    "clip": 1.0,
    "l2_loss": {
      ".*module/aggregation/weights.*": 0.001
    }
  },
  "features": {
    "seq_feat": "gold",
    "targets": [
      {
        "name": "gold",
        "key": "gold",
        "indices": {
          "O": 0
        },
        "unknown_word": "O",
        "pad_word": "O"
      }
    ],
    "inputs": [
      {
        "name": "elmo",
        "key": "word"
      },
      {
        "name": "predicate_index",
        "key": "predicate_index",
        "numeric": true,
        "rank": 1
      },
      {
        "name": "marker",
        "key": "marker",
        "config": {
          "dim": 100
        },
        "indices": {
          "0": 0
        },
        "unknown_word": "0",
        "pad_word": "0"
      }
    ]
  },
  "encoders": [
    {
      "name": "token_embedding",
      "type": "concat",
      "inputs": [
        "marker",
        "elmo"
      ],
      "input_dropout": 0.0
    },
    {
      "name": "alternating_lstm",
      "inputs": [
        "token_embedding"
      ],
      "type": "dblstm",
      "state_size": 300,
      "encoder_output_dropout": 0.1,
      "encoder_layers": 8
    }
  ],
  "heads": [
    {
      "encoder": "alternating_lstm",
      "name": "gold",
      "type": "biaffine-srl",
      "mlp_dim": 200,
      "mlp_dropout": 0.1,
      "label_smoothing": 0.1
    }
  ]
}